## NOTES:

1. **Expected directory structure**
```
project/
├── input_files/
│   ├── combined_training.extxyz
│   └── temp_300.0
├── input.yaml
├── nvt_simulation.in
├── run_allegro.sh
├── training_files/
└── h2o-deployed.pth
```
- **`project/`** → Example: `H2O`
- **`combined_training.extxyz`** → Contains all DFT frames; training/validation split is managed via `input.yaml`.
- **`temp_300.0/`** → Folder with the initial system snapshot generated by `box_initializer.py`.
- **`nvt_simulation.in`** → LAMMPS input file for NVT (or NPT) simulations.
- **`input.yaml`** → Allegro input configuration file.
- **`run_allegro.sh`** → SLURM `sbatch` script for job execution.
- **`training_files/`** → Stores logs, trained models, and datasets.
- **`h2o-deployed.pth`** → Final trained model.

---

## 🛠️ Run Script Best Practices
- **Avoid combining training and simulation run scripts** unless necessary.
- Training can be time-intensive, particularly for complex models.
- The **Allegro MLIP** developers provide configuration recommendations:  
  🔗 [Nequip Full Config](https://github.com/mir-group/nequip/blob/main/configs/full.yaml)

---

## 🖥️ CPU Usage for Training
- Using **multiple CPU cores** is recommended due to improved **data parsing parallelization** (from version **0.5.5+**).
- For details, see:  
  🔗 [Discussion: mir-group/nequip#182](https://github.com/mir-group/nequip/issues/182)  
  or consult the **0.5.5+ documentation**.

---

## 📊 Training, Validation & Test Sets
- Ensure that the **sum of training + validation data is < 100%** to leave space for testing.
- To evaluate trained models, use:
  ```bash
  nequip-evaluate

   - project -> e.g H2O
   - combined_training -> extxyz containing all DFT frames, training and validation split is done using
                    the input.yaml options.
   - temp_300.0 folder containing initializing snapshot generated by box_initializer.py
   - nvt_simulation.in -> LAMMPS input settings file for an NVT run, could also be NPT.
   - input.yaml -> Allegro input settings file
   - run_allegro.sh -> Job SBatch script
   - training_files -> contains logs, models, data from training
   - h2o-deployed.pth -> Final model derived from training

2. **Combining Run Scripts**
   - While it is technically possible to combine both run scripts, **it is not recommended**.  
   - Training, especially for complex models, can take a significant amount of time.  
   - Users should assess the **model complexity** based on their desired outputs.  
   - The creators of the Allegro MLIP provide recommendations in their `configs.yaml` file:  
     🔗 [Nequip Full Config](https://github.com/mir-group/nequip/blob/main/configs/full.yaml)

3. **CPU Usage for Training**
   - Using **more CPU cores** is highly recommended for training due to the implementation of data parsing 
     parallelization from **version 0.5.5 onwards**
   - For more details, refer to the following discussion:  
     🔗 [mir-group/nequip#182](https://github.com/mir-group/nequip/issues/182)  
   - Alternatively, review the **0.5.5 documentation** for a deeper understanding of the update.

4. **Managing Training, Validation, and Test Sets**
   - If you plan to create test sets, ensure that in your `input.yaml` file,  
     **the sum of training and validation datasets does not reach 100%**.  
   - You must leave some data aside for **testing**.  
   - Testing is performed using the following command:
     ```bash
     nequip-evaluate
     ```
